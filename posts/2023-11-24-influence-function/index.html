<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>What is Influence Function? | Thang's Blog</title><meta name=keywords content="Influence function"><meta name=description content="In this article, I review about Influence functions and various of its - a classic technique from robust statistics - to trace a model&rsquo;s prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction.
Basics of influence function Consider a prediction problem from some input space \(\mathcal{X}\) (e.g., images, text,\(\ldots\)) to an output space \(\mathcal{Y}\) (e.g,. labels)."><meta name=author content="Thang Nguyen-Duc"><link rel=canonical href=https://nducthang.github.io/posts/2023-11-24-influence-function/><link crossorigin=anonymous href=/assets/css/stylesheet.19ce2e35b67c1eb3628e21b8844ca2f72d2adf9d9c715e7e568a40f209923876.css integrity="sha256-Gc4uNbZ8HrNijiG4hEyi9y0q352ccV5+VopA8gmSOHY=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://nducthang.github.io/icon.png><link rel=icon type=image/png sizes=16x16 href=https://nducthang.github.io/icon.png><link rel=icon type=image/png sizes=32x32 href=https://nducthang.github.io/icon.png><link rel=apple-touch-icon href=https://nducthang.github.io/icon.png><link rel=mask-icon href=https://nducthang.github.io/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-MZBM3J5EX7"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-MZBM3J5EX7",{anonymize_ip:!1})}</script><meta property="og:title" content="What is Influence Function?"><meta property="og:description" content="In this article, I review about Influence functions and various of its - a classic technique from robust statistics - to trace a model&rsquo;s prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction.
Basics of influence function Consider a prediction problem from some input space \(\mathcal{X}\) (e.g., images, text,\(\ldots\)) to an output space \(\mathcal{Y}\) (e.g,. labels)."><meta property="og:type" content="article"><meta property="og:url" content="https://nducthang.github.io/posts/2023-11-24-influence-function/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-11-24T00:00:00+00:00"><meta property="article:modified_time" content="2023-11-24T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="What is Influence Function?"><meta name=twitter:description content="In this article, I review about Influence functions and various of its - a classic technique from robust statistics - to trace a model&rsquo;s prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction.
Basics of influence function Consider a prediction problem from some input space \(\mathcal{X}\) (e.g., images, text,\(\ldots\)) to an output space \(\mathcal{Y}\) (e.g,. labels)."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://nducthang.github.io/posts/"},{"@type":"ListItem","position":2,"name":"What is Influence Function?","item":"https://nducthang.github.io/posts/2023-11-24-influence-function/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"What is Influence Function?","name":"What is Influence Function?","description":"In this article, I review about Influence functions and various of its - a classic technique from robust statistics - to trace a model\u0026rsquo;s prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction.\nBasics of influence function Consider a prediction problem from some input space \\(\\mathcal{X}\\) (e.g., images, text,\\(\\ldots\\)) to an output space \\(\\mathcal{Y}\\) (e.g,. labels).","keywords":["Influence function"],"articleBody":"   In this article, I review about Influence functions and various of its - a classic technique from robust statistics - to trace a model’s prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction.\nBasics of influence function Consider a prediction problem from some input space \\(\\mathcal{X}\\) (e.g., images, text,\\(\\ldots\\)) to an output space \\(\\mathcal{Y}\\) (e.g,. labels). We are given training points \\(z_1,\\ldots,z_n\\), where \\(z_i=(x_i,y_i) \\in \\mathcal{X} \\times \\mathcal{Y}\\). For a point \\(z\\) and parameters \\(\\theta \\in \\Theta\\), let \\(L(z, \\theta)\\) be the loss, and let \\(\\frac{1}{n} \\sum_{i=1}^n L(z_i, \\theta)\\) be the empirical risk. The empirical risk minimizer is given by $$ \\hat{\\theta} \\stackrel{\\text { def }}{=} \\arg \\min _{\\theta \\in \\Theta} \\frac{1}{n} \\sum_{i=1}^{n} L\\left(z_{i}, \\theta\\right) $$ Assume that the empirical risk is twice-differentiable and strictly convex in \\(\\theta\\). Our goal is to understand the effect of training points on a model's predictions. Up-weighting a training point  Up-weighting a training example \\(z\\) by an infinitesimal amount \\(\\epsilon\\) leads to a new set of model parameters denoted by \\(\\hat{\\theta}_{\\epsilon, z}\\). This set of new model parameters \\(\\hat{\\theta}_{\\epsilon, z}\\) is obtained by solving: $$ \\hat{\\theta}_{\\epsilon, z} \\stackrel{\\text { def }}{=} \\arg \\min _{\\theta \\in \\Theta} \\frac{1}{n} \\sum_{i=1}^{n} L\\left(z_{i}, \\theta\\right)+\\epsilon L(z, \\theta) $$ Removing a training point \\(z\\) is similar to up-weighting its corresponding weight by \\(\\epsilon = \\frac{-1}{n}\\) in below equation. The main idea used is to approximate \\(\\hat{\\theta}_{\\epsilon, z}\\) by the first-order Taylor series expansion around the optimal model parameters represented by \\(\\theta^{*}\\), which leads to: $$ \\hat{\\theta}_{\\epsilon, z} \\approx \\theta^{*} - \\epsilon H_{\\hat{\\theta}}^{-1} \\nabla_{\\theta} L(z, \\hat{\\theta}) $$ where \\(H_{\\hat{\\theta}} \\stackrel{\\text { def }}{=} \\frac{1}{n} \\sum_{i=1}^{n} \\nabla_{\\theta}^{2} L\\left(z_{i}, \\hat{\\theta}\\right)\\) is the Hessian and is positive definite (PD) by assumption. Following the result in Pang Wei Koh and Percy Liang1, the change in the model parameters (\\(\\Delta\\theta = \\hat{\\theta}_{-z} - \\hat{\\theta} \\approx - \\frac{1}{n} \\mathcal{I}_{\\text {up,params }} (z)\\): $$ \\left.\\mathcal{I}_{\\text {up,params }}(z) \\stackrel{\\text { def }}{=} \\frac{d \\hat{\\theta}_{\\epsilon, z}}{d \\epsilon}\\right|_{\\epsilon=0}=-H_{\\hat{\\theta}}^{-1} \\nabla_{\\theta} L(z, \\hat{\\theta}) $$ The change in the loss value for a particular test point \\(z_t\\) when a training point \\(z\\) is up-weighted can be approximated as a closed-form expression by the chain rule: $$ \\begin{aligned} \\mathcal{I}_{\\text {up,loss }}\\left(z, z_{\\text {test }}\\right) \u0026\\left.\\stackrel{\\text { def }}{=} \\frac{d L\\left(z_{\\text {test }}, \\hat{\\theta}_{\\epsilon, z}\\right)}{d \\epsilon}\\right|_{\\epsilon=0} \\\\ \u0026=\\left.\\nabla_{\\theta} L\\left(z_{\\text {test }}, \\hat{\\theta}\\right)^{\\top} \\frac{d \\hat{\\theta}_{\\epsilon, z}}{d \\epsilon}\\right|_{\\epsilon=0} \\\\ \u0026=-\\nabla_{\\theta} L\\left(z_{\\text {test }}, \\hat{\\theta}\\right)^{\\top} H_{\\hat{\\theta}}^{-1} \\nabla_{\\theta} L(z, \\hat{\\theta}) . \\end{aligned} $$ Below equation is approximately the change in the loss for the test-sample \\(z_{\\text{test}}\\) when a training sample \\(z\\) is removed from the training set. In addition, in the paper 1, the authors also introduce Perturbing a training input. However, it is less common than up-weighting a training point.\nDeriving the influence function \\(\\mathcal{I}_{\\text{up, params}}\\) Recall that \\(\\hat{\\theta}\\) minimizes the empirical risk: $$ R(\\theta) \\stackrel{\\text { def }}{=} \\frac{1}{n} \\sum_{i=1}^{n} L\\left(z_{i}, \\theta\\right) $$ We further assume that \\(R\\) is twice-differentable and strongly convex in \\(\\theta\\), i.e: $$ H_{\\hat{\\theta}} \\stackrel{\\text { def }}{=} \\nabla^{2} R(\\hat{\\theta})=\\frac{1}{n} \\sum_{i=1}^{n} \\nabla_{\\theta}^{2} L\\left(z_{i}, \\hat{\\theta}\\right) $$ exits and is positive definite. This guarantees the existence of \\(H_{\\hat{\\theta}}^{-1}\\), which we will use in the subsequent derivation. The perturbed parameters \\(\\hat{\\theta}_{\\epsilon, z}\\) can be written as: $$ \\hat{\\theta}_{\\epsilon, z}=\\arg \\min _{\\theta \\in \\Theta}\\{R(\\theta)+\\epsilon L(z, \\theta)\\} $$ Define the parameter change \\(\\Delta_{\\epsilon} = \\hat{\\theta}_{\\epsilon,z} - \\hat{\\theta}\\), and note that, as \\(\\hat{\\theta}\\) doesn't depend on \\(\\epsilon\\), the quantity we seek to compute can be written in terms of it: $$ \\frac{d \\hat{\\theta}_{\\epsilon, z}}{d \\epsilon}=\\frac{d \\Delta_{\\epsilon}}{d \\epsilon} $$ Since \\(\\hat{\\theta}_{\\epsilon, z}\\) is a minimizer of above equation, let us examine its first-order optimality conditions: $$ 0=\\nabla R\\left(\\hat{\\theta}_{\\epsilon, z}\\right)+\\epsilon \\nabla L\\left(z, \\hat{\\theta}_{\\epsilon, z}\\right) $$ Next, since \\(\\hat{\\theta}_{\\epsilon, z} \\to \\hat{\\theta}\\) as \\(\\epsilon \\to 0\\), we perform a Taylor expansion of the right-band side: $$ \\begin{aligned} 0 \\approx \u0026[\\nabla R(\\hat{\\theta})+\\epsilon \\nabla L(z, \\hat{\\theta})]+\\\\ \u0026\\left[\\nabla^{2} R(\\hat{\\theta})+\\epsilon \\nabla^{2} L(z, \\hat{\\theta})\\right] \\Delta_{\\epsilon} \\end{aligned} $$ where we have dropped \\(o\\left(\\left\\|\\Delta_{\\epsilon}\\right\\|\\right)\\) terms. Solving for \\(\\Delta_{\\epsilon}\\), we get: $$ \\begin{array}{c} \\Delta_{\\epsilon} \\approx-\\left[\\nabla^{2} R(\\hat{\\theta})+\\epsilon \\nabla^{2} L(z, \\hat{\\theta})\\right]^{-1} \\\\ {[\\nabla R(\\hat{\\theta})+\\epsilon \\nabla L(z, \\hat{\\theta})]} \\end{array} $$ since \\(\\hat{\\theta}\\) minimizes \\(R\\), we have \\(\\nabla R(\\hat{\\theta})=0\\). Dropping \\(o(\\epsilon)\\) terms, we have: $$ \\Delta_{\\epsilon} \\approx-\\nabla^{2} R(\\hat{\\theta})^{-1} \\nabla L(z, \\hat{\\theta}) \\epsilon $$ So, we conclude that: $$ \\begin{aligned} \\left.\\frac{d \\hat{\\theta}_{\\epsilon, z}}{d \\epsilon}\\right|_{\\epsilon=0} \u0026=-H_{\\hat{\\theta}}^{-1} \\nabla L(z, \\hat{\\theta}) \\\\ \u0026 \\stackrel{\\text { def }}{=} \\mathcal{I}_{\\text {up,params }}(z) \\end{aligned} $$ Efficiently calculating influence Hessian-vector products  It is not easy and expensive to compute the matrix \\(H_{\\theta}^{-1}\\) directly. We can use Hessian-vector products (HVPs) to efficiently approximate \\(s_{\\text {test }} \\stackrel{\\text { def }}{=} H_{\\hat{\\theta}}^{-1} \\nabla_{\\theta} L\\left(z_{\\text {test }}, \\hat{\\theta}\\right)\\) and then compute \\(\\mathcal{I}_{\\text {up,loss }}\\left(z, z_{\\text {test }}\\right)=-s_{\\text {test }} \\cdot \\nabla_{\\theta} L(z, \\hat{\\theta})\\). With \\(s_{\\text{test}}\\), we can recursively compute the following: $$ \\left\\{ \\begin{matrix} H^{-1}_{0} v = v \\\\ H_j^{-1}v = v + (I-\\nabla^2_{\\theta} L(z_{s_j}, \\hat{\\theta})) H_{j-1}^{-1}v \\end{matrix} \\right. $$ Initialization: \\(v = \\nabla_{\\theta} L(z_{test}, \\hat{\\theta})\\), the \\(z_{s_j}\\) points are randomly taken from the training set. Equation equivalent: $$ \\left\\{ \\begin{matrix} H^{-1}_{0} v = v \\\\ H_j^{-1}v = v + IH_{j-1}^{-1}v - \\nabla^2_{\\theta} L(z_{s_j}, \\hat{\\theta}) H_{j-1}^{-1}v \\end{matrix} \\right. $$ The third component of the above equation is equivalent to calculating \\(\\mathbf{Hv}\\) where: \\(\\mathbf{H}=\\nabla^2_{\\theta} L(z_{s_j}, \\hat{\\theta})\\) and \\(\\mathbf{v}=H_{j-1}^{-1}v\\). In Heterogeneous uncertainty sampling for supervised learning2, we have: $$ \\mathbf{H} \\mathbf{v}=\\nabla_{\\mathbf{\\theta}}\\left(\\mathbf{v} \\cdot \\nabla_{\\mathbf{\\theta}} L\\right) $$ In influence function calculated as above, cost and approximation quality depends:\n J: the number of recursive iterations. T: the number of independent runs. B: the batch size of sample points from training data (Number of \\(z_{s_j}\\) ). To improve the speed of influence function, the paper Fastif: Scalable influence functions for efficient model interpretation and debugging 3 suggest some ideas such as: Speeding up the argmax using kNN, Speeding up the Inverse Hessian, Parallelization.  Speeding up the argmax using kNN  With the influence function, we need to calculate influence on the full training data. $$ z^{*}=\\underset{z \\in \\mathcal{Z}}{\\arg \\max } \\mathcal{I}\\left(z, z_{\\text {test }}\\right) $$ We hypothesize that we could constrain the expensive search to a subset of promising data points, \\(\\hat{\\mathcal{Z}} \\subseteq \\mathcal{Z}\\): $$ z^{*}=\\underset{z \\in \\hat{\\mathcal{Z}}}{\\arg \\max } \\mathcal{I}\\left(z, z_{\\text {test }}\\right) $$ We can select subset \\(\\hat{\\mathcal{Z}}\\) as the top-k nearest neighbors of \\(z_{\\text{test}}\\) based on the \\(L_{2}\\) distance between extracted features of the data-points and can use libraries such as FAISS 4.\nTo evaluate, define the recall score R@m as the percentage of top-m ground-truth influential data points selected by the kNN. $$ R @ m=\\frac{\\mid\\{\\text { retrieved }\\} \\cap\\{\\text { top- } m \\text { influential }\\} \\mid}{\\mid\\{\\text { top- } m \\text { influential } \\mid} $$ Speeding up the Inverse Hessian Propose a few simple changes:\n Choose a J so that approximation converges. Choose a small batch size. In our experiments, we found that even B = 1 suffices. Make up for the noisiness of small batch size using larger T , which can be distributed over multiple GPUs.  Parallelization We can apply asynchronous parallel computation to compute the \\(s_{\\text{test}}\\), use one synchronization point to average the result using all-reduce, and then asynchronously compute the influence of a subset of data-points that are pre-selected using kNN Influence functions in deep learning are fragile The influence function method is unstable in deep learning networks. According to the theory of influence functions, they work well with convex functions. However, it is not clear for non-convex functions. In the paper Influence functions in deep learning are fragile 5 provides comparative experiments on influence functions in networks with different depths and with different data. Experimentally, the authors concluded that:\n Influence function estimates fairly accurately when networks are shallow, not so well in deeper networks. Train model with weight decay \\(\\lambda\\| \\theta \\|_2^2\\) into the loss function to increase accuracy. The accuracy of influence can vary considerably depending on the test points.  Based on theory and experiment, I see that the influence function does not work effectively with non-convex optimization problems. This is also the biggest drawback of this method.\n  Pang Wei Koh and Percy Liang. “Understanding black-box predictions via influence functions”. In: International Conference on Machine Learning. ↩︎\n David D Lewis and Jason Catlett. “Heterogeneous uncertainty sampling for supervised learning”. In: Machine learning proceedings 1994. Elsevier, 1994, pp. 148–156. ↩︎\n Han Guo et al. “Fastif: Scalable influence functions for efficient model interpretation and debugging”. In: arXiv preprint arXiv:2012.15781 (2020). ↩︎\n Jeff Johnson, Matthijs Douze, and Herve Jegou. “Billion-scale similarity searchwith gpus”. In: IEEE Transactions on Big Data (2019). ↩︎\n Samyadeep Basu, Philip Pope, and Soheil Feizi. “Influence functions in deep learning are fragile”. In: arXiv preprint arXiv:2006.14651 (2020). ↩︎\n   ","wordCount":"1406","inLanguage":"en","datePublished":"2023-11-24T00:00:00Z","dateModified":"2023-11-24T00:00:00Z","author":{"@type":"Person","name":"Thang Nguyen-Duc"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://nducthang.github.io/posts/2023-11-24-influence-function/"},"publisher":{"@type":"Organization","name":"Thang's Blog","logo":{"@type":"ImageObject","url":"https://nducthang.github.io/icon.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://nducthang.github.io/ accesskey=h title="Thang's Blog (Alt + H)"><img src=https://nducthang.github.io/icon.png alt aria-label=logo height=50>Thang's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://nducthang.github.io/ title=Home><span>Home</span></a></li><li><a href=https://nducthang.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://nducthang.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://nducthang.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://nducthang.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://nducthang.github.io/posts/>Posts</a></div><h1 class=post-title>What is Influence Function?</h1><div class=post-meta><span title="2023-11-24 00:00:00 +0000 UTC">November 24, 2023</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;Thang Nguyen-Duc</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#basics-of-influence-function aria-label="Basics of influence function">Basics of influence function</a><ul><li><a href=#up-weighting-a-training-point aria-label="Up-weighting a training point">Up-weighting a training point</a></li><li><a href=#deriving-the-influence-function-hahahugoshortcode-s4-hbhb aria-label="Deriving the influence function \(\mathcal{I}_{\text{up, params}}\)">Deriving the influence function \(\mathcal{I}_{\text{up, params}}\)</a></li></ul></li><li><a href=#efficiently-calculating-influence aria-label="Efficiently calculating influence">Efficiently calculating influence</a><ul><li><a href=#hessian-vector-products aria-label="Hessian-vector products">Hessian-vector products</a></li><li><a href=#speeding-up-the-argmax-using-knn aria-label="Speeding up the argmax using kNN">Speeding up the argmax using kNN</a></li><li><a href=#speeding-up-the-inverse-hessian aria-label="Speeding up the Inverse Hessian">Speeding up the Inverse Hessian</a></li><li><a href=#parallelization aria-label=Parallelization>Parallelization</a></li></ul></li><li><a href=#influence-functions-in-deep-learning-are-fragile aria-label="Influence functions in deep learning are fragile">Influence functions in deep learning are fragile</a></li></ul></div></details></div><div class=post-content><p><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script>
In this article, I review about Influence functions and various of its - a classic technique from robust statistics - to trace a model&rsquo;s prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction.</p><h1 id=basics-of-influence-function>Basics of influence function<a hidden class=anchor aria-hidden=true href=#basics-of-influence-function>#</a></h1>Consider a prediction problem from some input space \(\mathcal{X}\) (e.g., images, text,\(\ldots\)) to an output space \(\mathcal{Y}\) (e.g,. labels). We are given training points \(z_1,\ldots,z_n\), where \(z_i=(x_i,y_i) \in \mathcal{X} \times \mathcal{Y}\). For a point \(z\) and parameters \(\theta \in \Theta\), let \(L(z, \theta)\) be the loss, and let \(\frac{1}{n} \sum_{i=1}^n L(z_i, \theta)\) be the empirical risk. The empirical risk minimizer is given by
$$
\hat{\theta} \stackrel{\text { def }}{=} \arg \min _{\theta \in \Theta} \frac{1}{n} \sum_{i=1}^{n} L\left(z_{i}, \theta\right)
$$
Assume that the empirical risk is twice-differentiable and strictly convex in \(\theta\). Our goal is to understand the effect of training points on a model's predictions.<h2 id=up-weighting-a-training-point>Up-weighting a training point<a hidden class=anchor aria-hidden=true href=#up-weighting-a-training-point>#</a></h2><p>Up-weighting a training example \(z\) by an infinitesimal amount \(\epsilon\) leads to a new set of model parameters denoted by \(\hat{\theta}_{\epsilon, z}\). This set of new model parameters \(\hat{\theta}_{\epsilon, z}\) is obtained by solving:
$$
\hat{\theta}_{\epsilon, z} \stackrel{\text { def }}{=} \arg \min _{\theta \in \Theta} \frac{1}{n} \sum_{i=1}^{n} L\left(z_{i}, \theta\right)+\epsilon L(z, \theta)
$$
Removing a training point \(z\) is similar to up-weighting its corresponding weight by \(\epsilon = \frac{-1}{n}\) in below equation. The main idea used is to approximate \(\hat{\theta}_{\epsilon, z}\) by the first-order Taylor series expansion around the optimal model parameters represented by \(\theta^{*}\), which leads to:
$$
\hat{\theta}_{\epsilon, z} \approx \theta^{*} - \epsilon H_{\hat{\theta}}^{-1} \nabla_{\theta} L(z, \hat{\theta})
$$
where \(H_{\hat{\theta}} \stackrel{\text { def }}{=} \frac{1}{n} \sum_{i=1}^{n} \nabla_{\theta}^{2} L\left(z_{i}, \hat{\theta}\right)\) is the Hessian and is positive definite (PD) by assumption.
Following the result in <cite>Pang Wei Koh and Percy Liang<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></cite>, the change in the model parameters (\(\Delta\theta = \hat{\theta}_{-z} - \hat{\theta} \approx - \frac{1}{n} \mathcal{I}_{\text {up,params }} (z)\):
$$
\left.\mathcal{I}_{\text {up,params }}(z) \stackrel{\text { def }}{=} \frac{d \hat{\theta}_{\epsilon, z}}{d \epsilon}\right|_{\epsilon=0}=-H_{\hat{\theta}}^{-1} \nabla_{\theta} L(z, \hat{\theta})
$$
The change in the loss value for a particular test point \(z_t\) when a training point \(z\) is up-weighted can be approximated as a closed-form expression by the chain rule:
$$
\begin{aligned}
\mathcal{I}_{\text {up,loss }}\left(z, z_{\text {test }}\right) &\left.\stackrel{\text { def }}{=} \frac{d L\left(z_{\text {test }}, \hat{\theta}_{\epsilon, z}\right)}{d \epsilon}\right|_{\epsilon=0} \\
&=\left.\nabla_{\theta} L\left(z_{\text {test }}, \hat{\theta}\right)^{\top} \frac{d \hat{\theta}_{\epsilon, z}}{d \epsilon}\right|_{\epsilon=0} \\
&=-\nabla_{\theta} L\left(z_{\text {test }}, \hat{\theta}\right)^{\top} H_{\hat{\theta}}^{-1} \nabla_{\theta} L(z, \hat{\theta}) .
\end{aligned}
$$
Below equation is approximately the change in the loss for the test-sample \(z_{\text{test}}\) when a training sample \(z\) is removed from the training set.
In addition, in the paper <cite><sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></cite>, the authors also introduce <em>Perturbing a training input</em>. However, it is less common than up-weighting a training point.</p><h2 id=deriving-the-influence-function-hahahugoshortcode-s4-hbhb>Deriving the influence function \(\mathcal{I}_{\text{up, params}}\)<a hidden class=anchor aria-hidden=true href=#deriving-the-influence-function-hahahugoshortcode-s4-hbhb>#</a></h2>Recall that \(\hat{\theta}\) minimizes the empirical risk:
$$
R(\theta) \stackrel{\text { def }}{=} \frac{1}{n} \sum_{i=1}^{n} L\left(z_{i}, \theta\right)
$$
We further assume that \(R\) is twice-differentable and strongly convex in \(\theta\), i.e:
$$
H_{\hat{\theta}} \stackrel{\text { def }}{=} \nabla^{2} R(\hat{\theta})=\frac{1}{n} \sum_{i=1}^{n} \nabla_{\theta}^{2} L\left(z_{i}, \hat{\theta}\right)
$$
exits and is positive definite. This guarantees the existence of \(H_{\hat{\theta}}^{-1}\), which we will use in the subsequent derivation.
The perturbed parameters \(\hat{\theta}_{\epsilon, z}\) can be written as:
$$
\hat{\theta}_{\epsilon, z}=\arg \min _{\theta \in \Theta}\{R(\theta)+\epsilon L(z, \theta)\}
$$
Define the parameter change \(\Delta_{\epsilon} = \hat{\theta}_{\epsilon,z} - \hat{\theta}\), and note that, as \(\hat{\theta}\) doesn't depend on \(\epsilon\), the quantity we seek to compute can be written in terms of it:
$$
\frac{d \hat{\theta}_{\epsilon, z}}{d \epsilon}=\frac{d \Delta_{\epsilon}}{d \epsilon}
$$
Since \(\hat{\theta}_{\epsilon, z}\) is a minimizer of above equation, let us examine its first-order optimality conditions:
$$
0=\nabla R\left(\hat{\theta}_{\epsilon, z}\right)+\epsilon \nabla L\left(z, \hat{\theta}_{\epsilon, z}\right)
$$
Next, since \(\hat{\theta}_{\epsilon, z} \to \hat{\theta}\) as \(\epsilon \to 0\), we perform a Taylor expansion of the right-band side:
$$
\begin{aligned}
0 \approx &[\nabla R(\hat{\theta})+\epsilon \nabla L(z, \hat{\theta})]+\\
&\left[\nabla^{2} R(\hat{\theta})+\epsilon \nabla^{2} L(z, \hat{\theta})\right] \Delta_{\epsilon}
\end{aligned}
$$
where we have dropped \(o\left(\left\|\Delta_{\epsilon}\right\|\right)\) terms.
Solving for \(\Delta_{\epsilon}\), we get:
$$
\begin{array}{c}
\Delta_{\epsilon} \approx-\left[\nabla^{2} R(\hat{\theta})+\epsilon \nabla^{2} L(z, \hat{\theta})\right]^{-1} \\
{[\nabla R(\hat{\theta})+\epsilon \nabla L(z, \hat{\theta})]}
\end{array}
$$
since \(\hat{\theta}\) minimizes \(R\), we have \(\nabla R(\hat{\theta})=0\). Dropping \(o(\epsilon)\) terms, we have:
$$
\Delta_{\epsilon} \approx-\nabla^{2} R(\hat{\theta})^{-1} \nabla L(z, \hat{\theta}) \epsilon
$$
So, we conclude that:
$$
\begin{aligned}
\left.\frac{d \hat{\theta}_{\epsilon, z}}{d \epsilon}\right|_{\epsilon=0} &=-H_{\hat{\theta}}^{-1} \nabla L(z, \hat{\theta}) \\
& \stackrel{\text { def }}{=} \mathcal{I}_{\text {up,params }}(z)
\end{aligned}
$$<h1 id=efficiently-calculating-influence>Efficiently calculating influence<a hidden class=anchor aria-hidden=true href=#efficiently-calculating-influence>#</a></h1><h2 id=hessian-vector-products>Hessian-vector products<a hidden class=anchor aria-hidden=true href=#hessian-vector-products>#</a></h2><p>It is not easy and expensive to compute the matrix \(H_{\theta}^{-1}\) directly. We can use Hessian-vector products (HVPs) to efficiently approximate \(s_{\text {test }} \stackrel{\text { def }}{=} H_{\hat{\theta}}^{-1} \nabla_{\theta} L\left(z_{\text {test }}, \hat{\theta}\right)\) and then compute \(\mathcal{I}_{\text {up,loss }}\left(z, z_{\text {test }}\right)=-s_{\text {test }} \cdot \nabla_{\theta} L(z, \hat{\theta})\). With \(s_{\text{test}}\), we can recursively compute the following:
$$
\left\{
\begin{matrix}
H^{-1}_{0} v = v \\
H_j^{-1}v = v + (I-\nabla^2_{\theta} L(z_{s_j}, \hat{\theta})) H_{j-1}^{-1}v
\end{matrix}
\right.
$$
Initialization: \(v = \nabla_{\theta} L(z_{test}, \hat{\theta})\), the \(z_{s_j}\) points are randomly taken from the training set. Equation equivalent:
$$
\left\{
\begin{matrix}
H^{-1}_{0} v = v \\
H_j^{-1}v = v + IH_{j-1}^{-1}v - \nabla^2_{\theta} L(z_{s_j}, \hat{\theta}) H_{j-1}^{-1}v
\end{matrix}
\right.
$$
The third component of the above equation is equivalent to calculating \(\mathbf{Hv}\) where: \(\mathbf{H}=\nabla^2_{\theta} L(z_{s_j}, \hat{\theta})\) and \(\mathbf{v}=H_{j-1}^{-1}v\). In <cite>Heterogeneous uncertainty sampling for supervised learning<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></cite>, we have:
$$
\mathbf{H} \mathbf{v}=\nabla_{\mathbf{\theta}}\left(\mathbf{v} \cdot \nabla_{\mathbf{\theta}} L\right)
$$
In influence function calculated as above, cost and approximation quality depends:</p><ul><li><strong>J</strong>: the number of recursive iterations.</li><li><strong>T</strong>: the number of independent runs.</li><li><strong>B</strong>: the batch size of sample points from training data (Number of \(z_{s_j}\) ).
To improve the speed of influence function, the paper <cite>Fastif: Scalable influence functions for efficient model interpretation and debugging <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup></cite> suggest some ideas such as: Speeding up the argmax using <em>kNN, Speeding up the Inverse Hessian, Parallelization</em>.</li></ul><h2 id=speeding-up-the-argmax-using-knn>Speeding up the argmax using kNN<a hidden class=anchor aria-hidden=true href=#speeding-up-the-argmax-using-knn>#</a></h2><p>With the influence function, we need to calculate influence on the full training data.
$$
z^{*}=\underset{z \in \mathcal{Z}}{\arg \max } \mathcal{I}\left(z, z_{\text {test }}\right)
$$
We hypothesize that we could constrain the expensive search to a subset of promising data points, \(\hat{\mathcal{Z}} \subseteq \mathcal{Z}\):
$$
z^{*}=\underset{z \in \hat{\mathcal{Z}}}{\arg \max } \mathcal{I}\left(z, z_{\text {test }}\right)
$$
We can select subset \(\hat{\mathcal{Z}}\) as the top-k nearest neighbors of \(z_{\text{test}}\) based on the \(L_{2}\) distance between extracted features of the data-points and can use libraries such as FAISS <sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>.</p><p>To evaluate, define the recall score R@m as the percentage of top-m ground-truth influential data points selected by the kNN.
$$
R @ m=\frac{\mid\{\text { retrieved }\} \cap\{\text { top- } m \text { influential }\} \mid}{\mid\{\text { top- } m \text { influential } \mid}
$$</p><h2 id=speeding-up-the-inverse-hessian>Speeding up the Inverse Hessian<a hidden class=anchor aria-hidden=true href=#speeding-up-the-inverse-hessian>#</a></h2><p>Propose a few simple changes:</p><ul><li>Choose a <strong>J</strong> so that approximation converges.</li><li>Choose a small batch size. In our experiments, we found that even <strong>B = 1</strong> suffices.</li><li>Make up for the noisiness of small batch size using larger <strong>T</strong> , which can be distributed over multiple GPUs.</li></ul><h2 id=parallelization>Parallelization<a hidden class=anchor aria-hidden=true href=#parallelization>#</a></h2><p><img loading=lazy src=7.png alt="parallel IF">
We can apply asynchronous parallel computation to compute the \(s_{\text{test}}\), use one synchronization point to average the result using all-reduce, and then asynchronously compute the influence of a subset of data-points that are pre-selected using kNN</p><h1 id=influence-functions-in-deep-learning-are-fragile>Influence functions in deep learning are fragile<a hidden class=anchor aria-hidden=true href=#influence-functions-in-deep-learning-are-fragile>#</a></h1><p>The influence function method is unstable in deep learning networks. According to the theory of influence functions, they work well with convex functions. However, it is not clear for non-convex functions. In the paper <cite>Influence functions in deep learning are fragile <sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup></cite> provides comparative experiments on influence functions in networks with different depths and with different data. Experimentally, the authors concluded that:</p><ul><li>Influence function estimates fairly accurately when networks are shallow, not so well in deeper networks.</li><li>Train model with weight decay \(\lambda\| \theta \|_2^2\) into the loss function to increase accuracy.</li><li>The accuracy of influence can vary considerably depending on the test points.</li></ul><p>Based on theory and experiment, I see that the influence function does not work effectively with non-convex optimization problems. This is also the biggest drawback of this method.</p><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>Pang Wei Koh and Percy Liang. “Understanding black-box predictions via influence functions”. In: International Conference on Machine Learning.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2 role=doc-endnote><p>David D Lewis and Jason Catlett. “Heterogeneous uncertainty sampling for supervised learning”. In: Machine learning proceedings 1994. Elsevier, 1994, pp. 148–156.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3 role=doc-endnote><p>Han Guo et al. “Fastif: Scalable influence functions for efficient model interpretation and debugging”. In: arXiv preprint arXiv:2012.15781 (2020).&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4 role=doc-endnote><p>Jeff Johnson, Matthijs Douze, and Herve Jegou. “Billion-scale similarity searchwith gpus”. In: IEEE Transactions on Big Data (2019).&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5 role=doc-endnote><p>Samyadeep Basu, Philip Pope, and Soheil Feizi. “Influence functions in deep learning are fragile”. In: arXiv preprint arXiv:2006.14651 (2020).&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></div><footer class=post-footer><ul class=post-tags><li><a href=https://nducthang.github.io/tags/influence-function/>Influence function</a></li></ul><nav class=paginav><a class=prev href=https://nducthang.github.io/posts/2023-11-25-gradient-based-methods/><span class=title>« Prev</span><br><span>Gradient-based methods in error detection</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share What is Influence Function? on x" href="https://x.com/intent/tweet/?text=What%20is%20Influence%20Function%3f&url=https%3a%2f%2fnducthang.github.io%2fposts%2f2023-11-24-influence-function%2f&hashtags=Influencefunction"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share What is Influence Function? on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fnducthang.github.io%2fposts%2f2023-11-24-influence-function%2f&title=What%20is%20Influence%20Function%3f&summary=What%20is%20Influence%20Function%3f&source=https%3a%2f%2fnducthang.github.io%2fposts%2f2023-11-24-influence-function%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share What is Influence Function? on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fnducthang.github.io%2fposts%2f2023-11-24-influence-function%2f&title=What%20is%20Influence%20Function%3f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share What is Influence Function? on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fnducthang.github.io%2fposts%2f2023-11-24-influence-function%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share What is Influence Function? on whatsapp" href="https://api.whatsapp.com/send?text=What%20is%20Influence%20Function%3f%20-%20https%3a%2f%2fnducthang.github.io%2fposts%2f2023-11-24-influence-function%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share What is Influence Function? on telegram" href="https://telegram.me/share/url?text=What%20is%20Influence%20Function%3f&url=https%3a%2f%2fnducthang.github.io%2fposts%2f2023-11-24-influence-function%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share What is Influence Function? on ycombinator" href="https://news.ycombinator.com/submitlink?t=What%20is%20Influence%20Function%3f&u=https%3a%2f%2fnducthang.github.io%2fposts%2f2023-11-24-influence-function%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://nducthang.github.io/>Thang's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerHTML="copy";function s(){e.innerHTML="copied!",setTimeout(()=>{e.innerHTML="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>