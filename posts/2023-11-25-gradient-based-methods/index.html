<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Gradient-based methods in error detection | Thang's Blog</title><meta name=keywords content="Influence function"><meta name=description content="I strongly encourage you to explore my earlier article, Understanding the Influence Function, as it serves as a valuable foundation for comprehending the content presented in this piece.
 What is error detection problem? The rapid growth of the internet, however, causes data to rise exponentially, posing numerous issues. Deep learning algorithms become less effective when big data is mislabeled or contains many errors. Current studies focus solely on improving the model rather than detecting data issues."><meta name=author content="Thang Nguyen-Duc"><link rel=canonical href=https://nducthang.github.io/posts/2023-11-25-gradient-based-methods/><link crossorigin=anonymous href=/assets/css/stylesheet.19ce2e35b67c1eb3628e21b8844ca2f72d2adf9d9c715e7e568a40f209923876.css integrity="sha256-Gc4uNbZ8HrNijiG4hEyi9y0q352ccV5+VopA8gmSOHY=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://nducthang.github.io/icon.png><link rel=icon type=image/png sizes=16x16 href=https://nducthang.github.io/icon.png><link rel=icon type=image/png sizes=32x32 href=https://nducthang.github.io/icon.png><link rel=apple-touch-icon href=https://nducthang.github.io/icon.png><link rel=mask-icon href=https://nducthang.github.io/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-MZBM3J5EX7"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-MZBM3J5EX7",{anonymize_ip:!1})}</script><meta property="og:title" content="Gradient-based methods in error detection"><meta property="og:description" content="I strongly encourage you to explore my earlier article, Understanding the Influence Function, as it serves as a valuable foundation for comprehending the content presented in this piece.
 What is error detection problem? The rapid growth of the internet, however, causes data to rise exponentially, posing numerous issues. Deep learning algorithms become less effective when big data is mislabeled or contains many errors. Current studies focus solely on improving the model rather than detecting data issues."><meta property="og:type" content="article"><meta property="og:url" content="https://nducthang.github.io/posts/2023-11-25-gradient-based-methods/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-11-25T00:00:00+00:00"><meta property="article:modified_time" content="2023-11-25T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Gradient-based methods in error detection"><meta name=twitter:description content="I strongly encourage you to explore my earlier article, Understanding the Influence Function, as it serves as a valuable foundation for comprehending the content presented in this piece.
 What is error detection problem? The rapid growth of the internet, however, causes data to rise exponentially, posing numerous issues. Deep learning algorithms become less effective when big data is mislabeled or contains many errors. Current studies focus solely on improving the model rather than detecting data issues."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://nducthang.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Gradient-based methods in error detection","item":"https://nducthang.github.io/posts/2023-11-25-gradient-based-methods/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Gradient-based methods in error detection","name":"Gradient-based methods in error detection","description":"I strongly encourage you to explore my earlier article, Understanding the Influence Function, as it serves as a valuable foundation for comprehending the content presented in this piece.\n What is error detection problem? The rapid growth of the internet, however, causes data to rise exponentially, posing numerous issues. Deep learning algorithms become less effective when big data is mislabeled or contains many errors. Current studies focus solely on improving the model rather than detecting data issues.","keywords":["Influence function"],"articleBody":"    I strongly encourage you to explore my earlier article, Understanding the Influence Function, as it serves as a valuable foundation for comprehending the content presented in this piece.\n What is error detection problem? The rapid growth of the internet, however, causes data to rise exponentially, posing numerous issues. Deep learning algorithms become less effective when big data is mislabeled or contains many errors. Current studies focus solely on improving the model rather than detecting data issues. Research on error tracing has not achieved high accuracy and is costly to store and compute, and is even void of stability or dependent on many different constraints and assumptions.\nThe model will work more accurately if the dataset is improved. Therefore, we concentrate on seeking solutions for resolving the problem of error tracing. We have a data set used to train the model, but it is enormous or requires a lot of expertise (such as in medical and engineering sectors); thus, people cannot manually check it. Besides, we will not be able to figure out how many incorrect patterns there are. Error detection problem to identify wrong data patterns in the original data set that we can modify to help improve the performance of deep learning models. The method in error dection problem must have high accuracy and fast access speed, minimize dependence on theoretical hypotheses, and be generalizable, suited for a wide range of data and deep learning models.\nIn this article, I will overview an approach to the error detection problem which is gradient-based methods, of which the Influence funtion in my previous article is one of those methods.\nRepresenter Points Representer Points 1 introduced by Yeh et al to approximate the influence function of training points on a test sample. To indicate the form of a representer theorem, suppose we solve for the optimal parameters: $$ \\theta^{*} = \\underset{\\theta \\in \\Theta}{\\text{argmin}} \\left\\{ \\frac{1}{n} \\sum_i^n L(x_i,y_i, \\theta) + g(\\| \\theta \\|) \\right\\} $$ where \\(g\\) is non-decreasing, \\(L_2\\) regularized. The parameterization spliting of the model as a feature model and a prediction network:  Feature model: \\(\\phi_2(x_i, \\theta_2)\\) can be arbitrarily deep, or simply the identify function. Prediction network: with parameters \\(\\theta_1\\) is \\(\\phi(x_i, \\theta) = \\theta_1 f_i \\subseteq \\mathbb{R}^c\\) and \\(f_i = \\phi_2 (x_i, \\theta_2) \\subseteq \\mathbb{R}^f\\) is the last intermedicate layer feature in the neural network for input \\(x_i\\). So, we have a prediction of model is \\(\\hat{y}_i = \\sigma\\left( \\phi(x_i, \\theta) \\right)\\) and let \\(g(\\| \\theta \\|) = \\lambda \\| \\theta_1 \\|^2\\). Then, we have the decomposition: $$ \\phi(x_t, \\theta^{*}) = \\sum_{i}^n k(x_t, x_i, \\alpha_i) $$ where \\(\\alpha_{i}=\\frac{1}{-2 \\lambda{n}} \\frac{\\partial \\mathcal{L}\\left(x_{i}, y_{i}, \\theta\\right)}{\\partial \\phi\\left(x_{i}, \\theta\\right)}\\) and \\(k(x_t, x_i, \\alpha_i)=\\alpha_i f_i^T f_t\\), which we call a representer value for \\(x_i\\) given \\(x_t\\). We showed that for such models the output for any target instance \\(x_t\\) can be expressed as a linear decomposition of “data importance” of training instances. Through this, we can evaluate when a testing point of the model predicts incorrectly which training points affect it the most, and expect that those training points are mislabeled data.   Proof: Note that for any stationary point, the gradient of the loss with respect to \\(\\theta_1\\) is equal to \\(0\\). We therefore have: $$ \\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\partial L\\left({x}_{i}, {y}_{i}, {\\theta}\\right)}{\\partial {\\theta}_{1}}+2 \\lambda {\\theta}_{1}^{*}=0 \\quad \\Rightarrow \\quad {\\theta}_{1}^{*}=-\\frac{1}{2 \\lambda n} \\sum_{i=1}^{n} \\frac{\\partial L\\left({x}_{i}, {y}_{i}, {\\theta}\\right)}{\\partial {\\theta}_{1}}=\\sum_{i=1}^{n} \\alpha_{i} {f}_{i}^{T} $$ where \\(\\alpha_{i}=\\frac{1}{-2 \\lambda{n}} \\frac{\\partial \\mathcal{L}\\left(x_{i}, y_{i}, \\theta\\right)}{\\partial \\phi\\left(x_{i}, \\theta\\right)}\\) by the chain rule. We thus have that: $$ \\phi(x_t, \\theta^{*}) = \\theta_1^{*} f_t = \\sum_{i}^n k(x_t, x_i, \\alpha) $$ where \\(k(x_t, x_i, \\alpha_i) = \\alpha_i f_i^T f_t\\) by simply plugging in the two above expression. Gradient Dot and Gradient Cosine Similarity These methods are introduced by Charpiat et al 2. Basically, these methods are based on influence function. If one wants to change the value of \\(L(z, \\theta)\\) by a small quantity \\(\\epsilon\\), one needs to update \\(\\theta\\) by \\(\\delta \\theta = \\epsilon \\frac{\\nabla_{\\theta}L(z, \\theta)}{\\| \\nabla_{\\theta} L(z, \\theta) \\|^2}\\). Indeed, after the parameter update, the new value at \\(z\\) will be: $$ L(z, \\theta + \\delta \\theta)(z) = L(z, \\theta) + \\nabla L(z, \\theta) \\cdot \\delta \\theta + O( \\| \\delta \\theta \\|) \\\\ = L(z, \\theta) + \\epsilon + O(\\epsilon^2) $$ This parameter change induces a value change at any other point \\(z'\\): $$ L(z', \\theta + \\delta \\theta) = L(z', \\theta) + \\nabla L(z', \\theta) \\cdot \\delta \\theta +O(\\| \\delta \\theta \\|) \\\\ = L(z', \\theta) + \\epsilon \\frac{\\nabla L(z', \\theta) \\cdot \\nabla L(z, \\theta)}{\\| \\nabla L(z, \\theta) \\|^2 } + O(\\epsilon^2) $$ Therefore the kernel represents the influence of $z$ over $z'$: $$ k_{\\theta}^N (z, z') = \\frac{\\nabla L(z', \\theta) \\cdot \\nabla L(z, \\theta)}{\\| \\nabla L(z, \\theta) \\|^2 } $$ Note however that \\(k_{\\theta}^N (x, x')\\) is not symmetric. We have two symmetric kernels natural arise:  The inner product: (We called it Gradient Dot) $$ k_{\\theta}^I (z, z') = \\nabla_{\\theta} L(z, \\theta) \\cdot \\nabla L(z', \\theta) $$  Normalized version: (We called it Gradient Cosine Similarity) $$ k_{\\theta}^C (z, z') = \\frac{\\nabla L(z, \\theta)}{\\|\\nabla L(z, \\theta) \\| } \\cdot \\frac{\\nabla L(z',\\theta)}{\\| \\nabla L(z', \\theta) \\|} $$ It can be seen that \\(k_{\\theta}^C (z, z')\\) has the advantage of being bounded (in \\([-1, 1]\\), thus expressing similarity in a usual meaning. Interestingly, \\(k_{\\theta}^I\\) is equivalent to the Influence function without Hessian, in An Empirical Comparison of Instance Attribution Methods for NLP 3 experimented and concluded that this formula is roughly equivalent to influence function with Hessian.  RelatIF method One shortcoming of influence functions is that the training examples deemed most influential are ofter outliers or mislabeled, making them poor choices for an explanation. RelatIF 4 is a new class of criteria for choosing relevant training examples by way of an optimization objective that places a constraint on global influence. Above figure described binary classification by linear decision boundaries (dashed line) to illustrate the difference between IF and RelatIF.\nIn figure (a), we can see that the model predicts the test input (star). As estimated by IF, the most influential training example for the prediction is an outlier (circled). Using RelatIF, the most effective training example is more typical (encased in a square).\nFigure (b) see that using IF, every test input falling within the shaded yellow region is most influenced by the same outlier (circled). Test inputs in the remaining white area are most influenced by one of 5 other high loss examples.\nFigure (c) using RelatIF, the area where test inputs are most affected by the outlier (circled) shrinks. Test inputs in the remaining region are most influenced by one of 65 other examples. To evaluate the effect of a training example \\(z_i\\) on testing example \\(z_{\\text{test}}\\), we have: $$ \\textbf{RelatIF}(z_i, z_{\\text{test}}) = \\cos \\left(H^{-\\frac{1}{2}} \\nabla_{\\theta} L(z_{\\text{test}}), H^{-\\frac{1}{2}} \\nabla_{\\theta} L(z_i) \\right) $$ where \\(\\cos\\) is cosine similarity function. TracIn method Introduction TracIn method 5 introduced by Garima and Freferick Liu et al. It computes the influence of a training example on a prediction made by the model. It applies to any machine learning model trained using stochastic gradient descent or variant, agnostic architecture, domain, and task.\nThe idealized notion of the influence of a particular training example \\(z\\) in a given test example \\(z'\\) is defined as the total reduction in loss on the test example \\(z'\\) that is induced by the training process whenever the training example \\(z\\) is utilized: $$ \\text{TracInIdeal(z,z')} = \\sum_{t:z_t =z} L(z', \\theta_t) - L(z', \\theta_{t+1}) $$ where \\(\\theta_t\\) and \\(\\theta_{t+1}\\) is parameters of model when using training example \\(z_t\\) with SGD to updating from \\(\\theta_t\\) to \\(\\theta_{t+1}\\). Suppose the initial parameter vector before starting the training process is \\(\\theta_0\\), and the final parameter vector is \\(\\theta_T\\). The iterative optimization technique operates on one training example at a time. Then: $$ \\sum_{i=1}^n \\text{TracInIdeal}(z_i,z') = L(z', \\theta_0) - L(z', \\theta_T) $$ Let:\n Proponents: Training samples that have positive value to influence score (reducing loss). Or so-called helpful/excitatory samples. Opponents: Training samples that have negative value to influence score (increase loss). Or so-called harmful/inhibitor samples   First-order Approximation to Idealized Influence We can approximate the change in the loss: $$ L(z',\\theta_{t+1}) = L(z',\\theta_t) + \\nabla L(z', \\theta_t) \\cdot (\\theta_{t+1} - \\theta_t) + O(\\|\\theta_{t+1} - \\theta_t \\|^2) $$ Using the training point \\(z_t\\) at iteration \\(t\\), then the change in parameters: $$ \\theta_{t+1} - \\theta_t = -\\eta_t \\nabla L(z_t, \\theta_t) $$ where \\(\\eta_t\\) is the step size in iteration \\(t\\). This formula should be changed appropriately if other optimization methods as AdaGrad, Adam, Newton,\\(\\ldots\\\\\\) Combining 2 above equations, we have: $$ L(z', \\theta_{t}) - L(z', \\theta_{t+1}) \\approx \\eta_t \\nabla L(z',\\theta_t) \\cdot (\\theta_{t+1} - \\theta_t) $$ The effect can be approximated for a training sample $z$ by summing the approximations over all iterations, where \\(z\\) is used to update the parameter. $$ \\text{TracIn}(z, z') = \\sum_{t:z_t=z} \\eta_t \\nabla L(z', \\theta_t) \\cdot \\nabla L(z, \\theta_t) $$ Extension to Minibatches To handle minibatches of size \\(b \\ge 1\\), we compute the influence of a minibatch on the test point \\(z'\\), and then take its first-order approximation: First-Order Approximation \\((B_t, z') = \\frac{1}{b} \\sum_{z \\in B_t} \\eta_t \\nabla L(z', \\theta_t) \\cdot \\nabla L(z, \\theta_t) \\), because the gradient for the minibatch \\(B_t\\) is \\(\\frac{1}{b} \\sum_{z \\in B_t} \\nabla L(z, \\theta_t)\\). Then, for each training point \\(z \\in B_t\\), we attribute the \\(\\frac{1}{b} \\cdot \\eta_t \\nabla L(z', \\theta_t) \\cdot \\nabla L(z, \\theta_t)\\) portion of the influence of \\(B_t\\) on the test point \\(z'\\). Summing up over all iteratios \\(t\\) in which a particular training point \\(z\\) was chosen in \\(B_t\\), we arrive at the following definition of TracIn with minibatches: $$ \\text{TracIn}(z, z') = \\frac{1}{b} \\sum_{t:z \\in B_t} \\eta_t \\nabla L(z', \\theta_t) \\cdot \\nabla L(z, \\theta_t) $$ TracIn with Checkpoint Suppose we have \\(k\\) checkpoints \\(\\theta_{t_1}, \\theta_{t_2},\\ldots,\\theta_{t_k}\\). We assume that between checkpoints, each training example is visited exactly once. And we use the notation \\(\\eta_i\\) to denote the step size between checkpoints \\(i-1\\) and \\(i\\). While the first-order approximation of the influence needs the parameter vector at the specific iteration where a given training example is visited, since we don't have access to the parameter vector, we approximate it with the first checkpoint parameter vector after it. Thus, this heuristic results: $$ \\text{TracInCP}(z,z') = \\sum_{i=1}^k \\eta_i \\nabla L(z, \\theta_{t_i}) \\cdot \\nabla L(z', \\theta_{t_i}) $$ Summary Through this article, I have introduced you to gradient-based methods employed in error detection tasks. While fundamentally providing satisfactory results, these gradient-based approaches demand significant computational resources and storage capacity.\n  Chih-Kuan Yeh et al. “Representer point selection for explaining deep neural networks”. In: arXiv preprint arXiv:1811.09720 (2018). ↩︎\n Guillaume Charpiat et al. “Input similarity from the neural network perspective”. In: NeurIPS 2019-33th Annual Conference on Neural Information Processing Systems. 2019. ↩︎\n Pouya Pezeshkpour et al. “An Empirical Comparison of Instance Attribution Methods for NLP”. In: arXiv preprint arXiv:2104.04128 (2021). ↩︎\n Elnaz Barshan, Marc-Etienne Brunet, and Gintare Karolina Dziugaite. “Relatif:Identifying explanatory training samples via relative influence”. In: International Conference on Artificial Intelligence and Statistics. PMLR. 2020, pp. 1899–1909. ↩︎\n Garima Pruthi et al. “Estimating training data influence by tracing gradient descent”. In: Advances in Neural Information Processing Systems 33 (2020), pp. 19920–19930. ↩︎\n   ","wordCount":"1836","inLanguage":"en","datePublished":"2023-11-25T00:00:00Z","dateModified":"2023-11-25T00:00:00Z","author":{"@type":"Person","name":"Thang Nguyen-Duc"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://nducthang.github.io/posts/2023-11-25-gradient-based-methods/"},"publisher":{"@type":"Organization","name":"Thang's Blog","logo":{"@type":"ImageObject","url":"https://nducthang.github.io/icon.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://nducthang.github.io/ accesskey=h title="Thang's Blog (Alt + H)"><img src=https://nducthang.github.io/icon.png alt aria-label=logo height=50>Thang's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://nducthang.github.io/ title=Home><span>Home</span></a></li><li><a href=https://nducthang.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://nducthang.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://nducthang.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://nducthang.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://nducthang.github.io/posts/>Posts</a></div><h1 class=post-title>Gradient-based methods in error detection</h1><div class=post-meta><span title="2023-11-25 00:00:00 +0000 UTC">November 25, 2023</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;Thang Nguyen-Duc</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#what-is-error-detection-problem aria-label="What is error detection problem?">What is error detection problem?</a></li><li><a href=#representer-points aria-label="Representer Points">Representer Points</a></li><li><a href=#gradient-dot-and-gradient-cosine-similarity aria-label="Gradient Dot and Gradient Cosine Similarity">Gradient Dot and Gradient Cosine Similarity</a></li><li><a href=#relatif-method aria-label="RelatIF method">RelatIF method</a></li><li><a href=#tracin-method aria-label="TracIn method">TracIn method</a><ul><li><a href=#introduction aria-label=Introduction>Introduction</a></li><li><a href=#first-order-approximation-to-idealized-influence aria-label="First-order Approximation to Idealized Influence">First-order Approximation to Idealized Influence</a></li><li><a href=#extension-to-minibatches aria-label="Extension to Minibatches">Extension to Minibatches</a></li><li><a href=#tracin-with-checkpoint aria-label="TracIn with Checkpoint">TracIn with Checkpoint</a></li></ul></li><li><a href=#summary aria-label=Summary>Summary</a></li></ul></div></details></div><div class=post-content><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script><blockquote><p>I strongly encourage you to explore my earlier article, Understanding the <a href=/posts/2023-11-24-influence-function/>Influence Function</a>, as it serves as a valuable foundation for comprehending the content presented in this piece.</p></blockquote><h1 id=what-is-error-detection-problem>What is error detection problem?<a hidden class=anchor aria-hidden=true href=#what-is-error-detection-problem>#</a></h1><p>The rapid growth of the internet, however, causes data to rise exponentially, posing numerous issues. Deep learning algorithms become less effective when big data is mislabeled or contains many errors. Current studies focus solely on improving the model rather than detecting data issues. Research on error tracing has not achieved high accuracy and is costly to store and compute, and is even void of stability or dependent on many different constraints and assumptions.</p><p>The model will work more accurately if the dataset is improved. Therefore, we concentrate on seeking solutions for resolving the problem of error tracing. We have a data set used to train the model, but it is enormous or requires a lot of expertise (such as in medical and engineering sectors); thus, people cannot manually check it. Besides, we will not be able to figure out how many incorrect patterns there are. Error detection problem to identify wrong data patterns in the original data set that we can modify to help improve the performance of deep learning models. The method in error dection problem must have high accuracy and fast access speed, minimize dependence on theoretical hypotheses, and be generalizable, suited for a wide range of data and deep learning models.</p><p>In this article, I will overview an approach to the error detection problem which is gradient-based methods, of which the Influence funtion in my previous article is one of those methods.</p><h1 id=representer-points>Representer Points<a hidden class=anchor aria-hidden=true href=#representer-points>#</a></h1><p><cite>Representer Points <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></cite> introduced by Yeh et al to approximate the influence function of training points on a test sample. To indicate the form of a representer theorem, suppose we solve for the optimal parameters:
$$
\theta^{*} = \underset{\theta \in \Theta}{\text{argmin}} \left\{ \frac{1}{n} \sum_i^n L(x_i,y_i, \theta) + g(\| \theta \|) \right\}
$$
where \(g\) is non-decreasing, \(L_2\) regularized. The parameterization spliting of the model as a feature model and a prediction network:</p><ul><li><strong>Feature model:</strong> \(\phi_2(x_i, \theta_2)\) can be arbitrarily deep, or simply the identify function.</li><li><strong>Prediction network:</strong> with parameters \(\theta_1\) is \(\phi(x_i, \theta) = \theta_1 f_i \subseteq \mathbb{R}^c\) and \(f_i = \phi_2 (x_i, \theta_2) \subseteq \mathbb{R}^f\) is the last intermedicate layer feature in the neural network for input \(x_i\).
So, we have a prediction of model is \(\hat{y}_i = \sigma\left( \phi(x_i, \theta) \right)\) and let \(g(\| \theta \|) = \lambda \| \theta_1 \|^2\). Then, we have the decomposition:
$$
\phi(x_t, \theta^{*}) = \sum_{i}^n k(x_t, x_i, \alpha_i)
$$
where \(\alpha_{i}=\frac{1}{-2 \lambda{n}} \frac{\partial \mathcal{L}\left(x_{i}, y_{i}, \theta\right)}{\partial \phi\left(x_{i}, \theta\right)}\) and \(k(x_t, x_i, \alpha_i)=\alpha_i f_i^T f_t\), which we call a representer value for \(x_i\) given \(x_t\).
We showed that for such models the output for any target instance \(x_t\) can be expressed as a linear decomposition of “data importance” of training instances. Through this, we can evaluate when a testing point of the model predicts incorrectly which training points affect it the most, and expect that those training points are mislabeled data.</li></ul><p><strong>Proof:</strong> Note that for any stationary point, the gradient of the loss with respect to \(\theta_1\) is equal to \(0\). We therefore have:
$$
\frac{1}{n} \sum_{i=1}^{n} \frac{\partial L\left({x}_{i}, {y}_{i}, {\theta}\right)}{\partial {\theta}_{1}}+2 \lambda {\theta}_{1}^{*}=0 \quad \Rightarrow \quad {\theta}_{1}^{*}=-\frac{1}{2 \lambda n} \sum_{i=1}^{n} \frac{\partial L\left({x}_{i}, {y}_{i}, {\theta}\right)}{\partial {\theta}_{1}}=\sum_{i=1}^{n} \alpha_{i} {f}_{i}^{T}
$$
where \(\alpha_{i}=\frac{1}{-2 \lambda{n}} \frac{\partial \mathcal{L}\left(x_{i}, y_{i}, \theta\right)}{\partial \phi\left(x_{i}, \theta\right)}\) by the chain rule. We thus have that:
$$
\phi(x_t, \theta^{*}) = \theta_1^{*} f_t = \sum_{i}^n k(x_t, x_i, \alpha)
$$
where \(k(x_t, x_i, \alpha_i) = \alpha_i f_i^T f_t\) by simply plugging in the two above expression.</p><h1 id=gradient-dot-and-gradient-cosine-similarity>Gradient Dot and Gradient Cosine Similarity<a hidden class=anchor aria-hidden=true href=#gradient-dot-and-gradient-cosine-similarity>#</a></h1><p>These methods are introduced by Charpiat et al <cite><sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></cite>. Basically, these methods are based on influence function. If one wants to change the value of \(L(z, \theta)\) by a small quantity \(\epsilon\), one needs to update \(\theta\) by \(\delta \theta = \epsilon \frac{\nabla_{\theta}L(z, \theta)}{\| \nabla_{\theta} L(z, \theta) \|^2}\). Indeed, after the parameter update, the new value at \(z\) will be:
$$
L(z, \theta + \delta \theta)(z) = L(z, \theta) + \nabla L(z, \theta) \cdot \delta \theta + O( \| \delta \theta \|) \\
= L(z, \theta) + \epsilon + O(\epsilon^2)
$$
This parameter change induces a value change at any other point \(z'\):
$$
L(z', \theta + \delta \theta) = L(z', \theta) + \nabla L(z', \theta) \cdot \delta \theta +O(\| \delta \theta \|) \\
= L(z', \theta) + \epsilon \frac{\nabla L(z', \theta) \cdot \nabla L(z, \theta)}{\| \nabla L(z, \theta) \|^2 } + O(\epsilon^2)
$$
Therefore the kernel represents the influence of $z$ over $z'$:
$$
k_{\theta}^N (z, z') = \frac{\nabla L(z', \theta) \cdot \nabla L(z, \theta)}{\| \nabla L(z, \theta) \|^2 }
$$
Note however that \(k_{\theta}^N (x, x')\) is not symmetric. We have two symmetric kernels natural arise:</p><ul><li><strong>The inner product:</strong> (We called it <strong>Gradient Dot</strong>)
$$
k_{\theta}^I (z, z') = \nabla_{\theta} L(z, \theta) \cdot \nabla L(z', \theta)
$$</li><li><strong>Normalized version:</strong> (We called it <strong>Gradient Cosine Similarity</strong>)
$$
k_{\theta}^C (z, z') = \frac{\nabla L(z, \theta)}{\|\nabla L(z, \theta) \| } \cdot \frac{\nabla L(z',\theta)}{\| \nabla L(z', \theta) \|}
$$
It can be seen that \(k_{\theta}^C (z, z')\) has the advantage of being bounded (in \([-1, 1]\), thus expressing similarity in a usual meaning. Interestingly, \(k_{\theta}^I\) is equivalent to the Influence function without Hessian, in <cite>An Empirical Comparison of Instance Attribution Methods for NLP <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup></cite> experimented and concluded that this formula is roughly equivalent to influence function with Hessian.</li></ul><h1 id=relatif-method>RelatIF method<a hidden class=anchor aria-hidden=true href=#relatif-method>#</a></h1><p>One shortcoming of influence functions is that the training examples deemed most <em>influential</em> are ofter outliers or mislabeled, making them poor choices for an explanation. <strong>RelatIF</strong> <cite><sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup></cite> is a new class of criteria for choosing relevant training examples by way of an optimization objective that places a constraint on global influence.
<img loading=lazy src=8.png alt=RelatIF>
Above figure described binary classification by linear decision boundaries (dashed line) to illustrate the difference between IF and RelatIF.</p><p>In figure (a), we can see that the model predicts the test input (star). As estimated by IF, the most influential training example for the prediction is an outlier (circled). Using RelatIF, the most effective training example is more typical (encased in a square).</p><p>Figure (b) see that using IF, every test input falling within the shaded yellow region is most influenced by the same outlier (circled). Test inputs in the remaining white area are most influenced by one of 5 other high loss examples.</p><p>Figure (c) using RelatIF, the area where test inputs are most affected by the outlier (circled) shrinks. Test inputs in the remaining region are most influenced by one of 65 other examples.
To evaluate the effect of a training example \(z_i\) on testing example \(z_{\text{test}}\), we have:
$$
\textbf{RelatIF}(z_i, z_{\text{test}}) = \cos \left(H^{-\frac{1}{2}} \nabla_{\theta} L(z_{\text{test}}), H^{-\frac{1}{2}} \nabla_{\theta} L(z_i) \right)
$$
where \(\cos\) is cosine similarity function.</p><h1 id=tracin-method>TracIn method<a hidden class=anchor aria-hidden=true href=#tracin-method>#</a></h1><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><p>TracIn method <cite><sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup></cite> introduced by Garima and Freferick Liu et al. It computes the influence of a training example on a prediction made by the model. It applies to any machine learning model trained using stochastic gradient descent or variant, agnostic architecture, domain, and task.</p>The idealized notion of the influence of a particular training example \(z\) in a given test example \(z'\) is defined as the total reduction in loss on the test example \(z'\) that is induced by the training process whenever the training example \(z\) is utilized:
$$
\text{TracInIdeal(z,z')} = \sum_{t:z_t =z} L(z', \theta_t) - L(z', \theta_{t+1})
$$
where \(\theta_t\) and \(\theta_{t+1}\) is parameters of model when using training example \(z_t\) with SGD to updating from \(\theta_t\) to \(\theta_{t+1}\). Suppose the initial parameter vector before starting the training process is \(\theta_0\), and the final parameter vector is \(\theta_T\). The iterative optimization technique operates on one training example at a time. Then:
$$
\sum_{i=1}^n \text{TracInIdeal}(z_i,z') = L(z', \theta_0) - L(z', \theta_T)
$$<p>Let:</p><ul><li><strong>Proponents:</strong> Training samples that have positive value to influence score (reducing loss). Or so-called helpful/excitatory samples.</li><li><strong>Opponents:</strong> Training samples that have negative value to influence score (increase loss). Or so-called harmful/inhibitor samples
<img loading=lazy src=9.png alt="Tracin method"></li></ul><h2 id=first-order-approximation-to-idealized-influence>First-order Approximation to Idealized Influence<a hidden class=anchor aria-hidden=true href=#first-order-approximation-to-idealized-influence>#</a></h2>We can approximate the change in the loss:
$$
L(z',\theta_{t+1}) = L(z',\theta_t) + \nabla L(z', \theta_t) \cdot (\theta_{t+1} - \theta_t) + O(\|\theta_{t+1} - \theta_t \|^2)
$$
Using the training point \(z_t\) at iteration \(t\), then the change in parameters:
$$
\theta_{t+1} - \theta_t = -\eta_t \nabla L(z_t, \theta_t)
$$
where \(\eta_t\) is the step size in iteration \(t\). This formula should be changed appropriately if other optimization methods as AdaGrad, Adam, Newton,\(\ldots\\\)
Combining 2 above equations, we have:
$$
L(z', \theta_{t}) - L(z', \theta_{t+1}) \approx \eta_t \nabla L(z',\theta_t) \cdot (\theta_{t+1} - \theta_t)
$$
The effect can be approximated for a training sample $z$ by summing the approximations over all iterations, where \(z\) is used to update the parameter.
$$
\text{TracIn}(z, z') = \sum_{t:z_t=z} \eta_t \nabla L(z', \theta_t) \cdot \nabla L(z, \theta_t)
$$<h2 id=extension-to-minibatches>Extension to Minibatches<a hidden class=anchor aria-hidden=true href=#extension-to-minibatches>#</a></h2>To handle minibatches of size \(b \ge 1\), we compute the influence of a minibatch on the test point \(z'\), and then take its first-order approximation: First-Order Approximation \((B_t, z') = \frac{1}{b} \sum_{z \in B_t} \eta_t \nabla L(z', \theta_t) \cdot \nabla L(z, \theta_t) \), because the gradient for the minibatch \(B_t\) is \(\frac{1}{b} \sum_{z \in B_t} \nabla L(z, \theta_t)\). Then, for each training point \(z \in B_t\), we attribute the \(\frac{1}{b} \cdot \eta_t \nabla L(z', \theta_t) \cdot \nabla L(z, \theta_t)\) portion of the influence of \(B_t\) on the test point \(z'\). Summing up over all iteratios \(t\) in which a particular training point \(z\) was chosen in \(B_t\), we arrive at the following definition of TracIn with minibatches:
$$
\text{TracIn}(z, z') = \frac{1}{b} \sum_{t:z \in B_t} \eta_t \nabla L(z', \theta_t) \cdot \nabla L(z, \theta_t)
$$<h2 id=tracin-with-checkpoint>TracIn with Checkpoint<a hidden class=anchor aria-hidden=true href=#tracin-with-checkpoint>#</a></h2>Suppose we have \(k\) checkpoints \(\theta_{t_1}, \theta_{t_2},\ldots,\theta_{t_k}\). We assume that between checkpoints, each training example is visited exactly once. And we use the notation \(\eta_i\) to denote the step size between checkpoints \(i-1\) and \(i\). While the first-order approximation of the influence needs the parameter vector at the specific iteration where a given training example is visited, since we don't have access to the parameter vector, we approximate it with the first checkpoint parameter vector after it. Thus, this heuristic results:
$$
\text{TracInCP}(z,z') = \sum_{i=1}^k \eta_i \nabla L(z, \theta_{t_i}) \cdot \nabla L(z', \theta_{t_i})
$$<h1 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h1><p>Through this article, I have introduced you to gradient-based methods employed in error detection tasks. While fundamentally providing satisfactory results, these gradient-based approaches demand significant computational resources and storage capacity.</p><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>Chih-Kuan Yeh et al. “Representer point selection for explaining deep neural networks”. In: arXiv preprint arXiv:1811.09720 (2018).&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2 role=doc-endnote><p>Guillaume Charpiat et al. “Input similarity from the neural network perspective”.
In: NeurIPS 2019-33th Annual Conference on Neural Information Processing Systems. 2019.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3 role=doc-endnote><p>Pouya Pezeshkpour et al. “An Empirical Comparison of Instance Attribution Methods for NLP”. In: arXiv preprint arXiv:2104.04128 (2021).&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4 role=doc-endnote><p>Elnaz Barshan, Marc-Etienne Brunet, and Gintare Karolina Dziugaite. “Relatif:Identifying explanatory training samples via relative influence”. In: International Conference on Artificial Intelligence and Statistics. PMLR. 2020, pp. 1899–1909.&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5 role=doc-endnote><p>Garima Pruthi et al. “Estimating training data influence by tracing gradient descent”. In: Advances in Neural Information Processing Systems 33 (2020), pp. 19920–19930.&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></div><footer class=post-footer><ul class=post-tags><li><a href=https://nducthang.github.io/tags/influence-function/>Influence function</a></li></ul><nav class=paginav><a class=prev href=https://nducthang.github.io/posts/2024-05-01-llm-large-language-model-families/><span class=title>« Prev</span><br><span>Large Language Model Families</span></a>
<a class=next href=https://nducthang.github.io/posts/2023-11-24-influence-function/><span class=title>Next »</span><br><span>What is Influence Function?</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Gradient-based methods in error detection on x" href="https://x.com/intent/tweet/?text=Gradient-based%20methods%20in%20error%20detection&url=https%3a%2f%2fnducthang.github.io%2fposts%2f2023-11-25-gradient-based-methods%2f&hashtags=Influencefunction"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Gradient-based methods in error detection on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fnducthang.github.io%2fposts%2f2023-11-25-gradient-based-methods%2f&title=Gradient-based%20methods%20in%20error%20detection&summary=Gradient-based%20methods%20in%20error%20detection&source=https%3a%2f%2fnducthang.github.io%2fposts%2f2023-11-25-gradient-based-methods%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Gradient-based methods in error detection on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fnducthang.github.io%2fposts%2f2023-11-25-gradient-based-methods%2f&title=Gradient-based%20methods%20in%20error%20detection"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Gradient-based methods in error detection on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fnducthang.github.io%2fposts%2f2023-11-25-gradient-based-methods%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Gradient-based methods in error detection on whatsapp" href="https://api.whatsapp.com/send?text=Gradient-based%20methods%20in%20error%20detection%20-%20https%3a%2f%2fnducthang.github.io%2fposts%2f2023-11-25-gradient-based-methods%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Gradient-based methods in error detection on telegram" href="https://telegram.me/share/url?text=Gradient-based%20methods%20in%20error%20detection&url=https%3a%2f%2fnducthang.github.io%2fposts%2f2023-11-25-gradient-based-methods%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Gradient-based methods in error detection on ycombinator" href="https://news.ycombinator.com/submitlink?t=Gradient-based%20methods%20in%20error%20detection&u=https%3a%2f%2fnducthang.github.io%2fposts%2f2023-11-25-gradient-based-methods%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://nducthang.github.io/>Thang's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerHTML="copy";function s(){e.innerHTML="copied!",setTimeout(()=>{e.innerHTML="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>